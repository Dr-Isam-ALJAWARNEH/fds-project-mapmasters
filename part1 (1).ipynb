{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"o5ahOQs7Q-KC"},"outputs":[],"source":["!pip install pygeohash\n","# Import Required Libraries\n","import os\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","from sklearn.cluster import DBSCAN\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error\n","from geopy.distance import great_circle\n","import pygeohash as pgh\n","import folium\n","from folium.plugins import MarkerCluster\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from shapely.geometry import Point\n","from shapely.ops import nearest_points\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 1: Mount Drive & Load AQ and Taxi Data\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set path to datasets folder\n","base_path = '/content/drive/MyDrive/Datasets/'\n","\n","# Load All Air Quality (AQ) Data\n","aq_dfs = []\n","\n","# Loop through AQ_data_1.csv to AQ_data_19.csv\n","for i in range(1, 20):\n","    file_path = os.path.join(base_path, f\"AQ_data_{i}.csv\")\n","\n","    if os.path.exists(file_path):\n","        df = pd.read_csv(file_path)\n","\n","        # Rename and keep relevant columns\n","        df = df.rename(columns={\n","            'Latitude': 'latitude',\n","            'Longitude': 'longitude',\n","            'ReadingDateTimeUTC': 'timestamp',\n","            'PM25': 'pm25'\n","        })\n","        df = df[['latitude', 'longitude', 'timestamp', 'pm25']]\n","\n","        # Print record count of the current AQ dataset\n","        print(f\"✅ Loaded AQ_data_{i}.csv with {len(df)} records\")\n","\n","        aq_dfs.append(df)\n","    else:\n","        print(f\" File not found: {file_path}\")\n","\n","# Combine all AQ files into a single DataFrame\n","aq_df = pd.concat(aq_dfs, ignore_index=True)\n","print(\" Preview of Combined AQ Data:\")\n","print(aq_df.head())\n","print(f\" Total AQ Records Loaded: {len(aq_df)}\")\n","\n","# Load All Taxi Trips Data\n","taxi_file_path = os.path.join(base_path, 'Taxi_Trips.csv')\n","\n","taxi_df = pd.read_csv(taxi_file_path, usecols=[\n","    'Trip Start Timestamp',\n","    'Trip Seconds',\n","    'Trip Miles',\n","    'Pickup Centroid Latitude',\n","    'Pickup Centroid Longitude'\n","])\n","\n","# Rename columns for consistency\n","taxi_df = taxi_df.rename(columns={\n","    'Trip Start Timestamp': 'trip_start_timestamp',\n","    'Pickup Centroid Latitude': 'pickup_latitude',\n","    'Pickup Centroid Longitude': 'pickup_longitude',\n","    'Trip Seconds': 'trip_seconds',\n","    'Trip Miles': 'trip_miles'\n","})\n","\n","print(\"\\n✅ Preview of Taxi Trips Data:\")\n","print(taxi_df.head())\n","print(f\"✅ Total Taxi Records Loaded: {len(taxi_df)}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iPET_6P_R1OR"},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMPuDXW457jbr77ZJzGjuri","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
