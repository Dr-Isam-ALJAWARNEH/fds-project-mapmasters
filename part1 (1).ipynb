# Import Required Libraries
# os is used for handling file paths and directory operations
import os
# pandas is used for data manipulation and analysis using DataFrames
import pandas as pd
# numpy provides support for numerical operations and array handling
import numpy as np
# geopandas extends pandas to handle geospatial data using shapefiles, geometry columns, etc.
import geopandas as gpd
# DBSCAN is a clustering algorithm from scikit-learn used for density-based clustering
from sklearn.cluster import KMeans, DBSCAN
# MinMaxScaler is used to scale features to a specified range, typically [0, 1]
from sklearn.preprocessing import MinMaxScaler
# mean_absolute_error is used to evaluate prediction performance by calculating average absolute errors
from sklearn.metrics import mean_absolute_error
# great_circle is used to calculate the shortest distance between two points on the Earth's surface
from geopy.distance import great_circle
# pygeohash is used for encoding latitude and longitude into geohash strings for spatial grouping
import pygeohash as pgh
# folium is used for interactive map visualization in Python
import folium
# MarkerCluster allows grouping markers in folium maps for better readability
from folium.plugins import MarkerCluster
# matplotlib is a standard plotting library for creating static, animated, and interactive visualizations
import matplotlib.pyplot as plt
# seaborn is a statistical data visualization library based on matplotlib, providing enhanced plots
import seaborn as sns
# shapely.geometry.Point is used to create point objects for spatial operations
from shapely.geometry import Point
# nearest_points is used to find the nearest point between two geometries
from shapely.ops import nearest_points
# google.colab.drive is used to mount Google Drive in Colab to access files stored there
from google.colab import drive
# Calculates the Silhouette Score, which is used to evaluate the quality of clustering results. A higher score indicates better-defined clusters.
from sklearn.metrics import silhouette_score
# Splits the dataset into training and testing subsets. This is typically used in machine learning to evaluate model performance by training on one set and testing on another.
from sklearn.model_selection import train_test_split
# Import folium for interactive map visualization of spatial data
import folium
